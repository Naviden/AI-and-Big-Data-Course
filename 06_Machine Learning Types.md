# Machine Learning Types


### Topics Covered:
- **Supervised Learning**
- **Unsupervised Learning**

### Objectives:
1. Understand the key differences between supervised and unsupervised learning.
2. Identify various algorithms used in both supervised and unsupervised learning.
3. Apply knowledge of these learning types to appropriate problem domains.

---

## 1. Supervised Learning

### Definition:
Supervised learning is a type of machine learning where the model is trained on a labeled dataset. This means that each training example is paired with an output label. The goal is to learn a mapping from inputs to the desired output.

### Key Concepts:
- **Training Data:** Labeled data used to train the model.
- **Labels:** The correct outputs associated with each training example.
- **Model Prediction:** The output generated by the model based on the input data.
- **Loss Function:** A function that measures the difference between the model's prediction and the true label. The model is trained to minimize this loss.

### Mathematical Formulation:
Given a dataset $D = \{(x_1, y_1), (x_2, y_2), \dots, (x_n, y_n)\}$ where $x_i$ represents the input features and $y_i$ the corresponding labels, the goal is to find a function $f(x)$ such that:

$$ f(x) \approx y $$

The function $f(x)$ is typically learned by minimizing a loss function $L(y, f(x))$:

$$ \text{Minimize} \sum_{i=1}^{n} L(y_i, f(x_i)) $$

### Common Algorithms:
- **Linear Regression:**
  - Used for predicting a continuous value.
  - Formula: $y = \beta_0 + \beta_1x_1 + \dots + \beta_nx_n + \epsilon$
- **Logistic Regression:**
  - Used for binary classification.
  - Formula: $P(y=1|x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1x_1 + \dots + \beta_nx_n)}}$
- **Support Vector Machines (SVM):**
  - Finds the hyperplane that best separates the classes.
  - Formula: $f(x) = \text{sign}(w \cdot x + b)$
- **Decision Trees:**
  - A tree-like model used for both classification and regression tasks.
  - Decision Rule: Split the data based on feature $x_j$ at threshold $t$.
- **Neural Networks:**
  - Complex models capable of capturing non-linear relationships.
  - Formula (for a single neuron): $a^{[l]} = g(W^{[l]}a^{[l-1]} + b^{[l]})$

### Examples:
- **Spam Detection:** Classifying emails as spam or not spam using labeled examples.
- **Credit Scoring:** Predicting the likelihood of a borrower defaulting on a loan based on historical data.

---

## 2. Unsupervised Learning

### Definition:
Unsupervised learning involves training a model on data that is not labeled. The goal is to infer the natural structure present within a set of data points.

### Key Concepts:
- **No Labels:** The model must learn from the features alone without supervision.
- **Clustering:** Grouping data points based on their similarities.
- **Dimensionality Reduction:** Reducing the number of features while preserving important information.

### Mathematical Formulation:
Given a dataset $D = \{x_1, x_2, \dots, x_n\}$, the goal is to find a function $g(x)$ that identifies patterns or groups in the data:

$$ g(x_i) \rightarrow \text{clusters or reduced features} $$

### Common Algorithms:
- **K-Means Clustering:**
  - Groups data into $k$ clusters by minimizing the variance within each cluster.
  - Objective: Minimize $\sum_{i=1}^{k} \sum_{x \in C_i} \| x - \mu_i \|^2$
- **Hierarchical Clustering:**
  - Builds a hierarchy of clusters without pre-specifying the number of clusters.
  - Uses methods like single linkage or complete linkage for clustering.
- **Principal Component Analysis (PCA):**
  - Reduces the dimensionality of data by transforming it into principal components.
  - Formula: $Z = XW$, where $W$ is the matrix of eigenvectors.
- **Autoencoders:**
  - Neural networks used for dimensionality reduction or feature learning.
  - Objective: Minimize the reconstruction error between the input and the output.

### Examples:
- **Customer Segmentation:** Grouping customers based on purchasing behavior for targeted marketing.
- **Anomaly Detection:** Identifying unusual patterns in data that do not conform to expected behavior, such as fraud detection.

---

### Recommended Reading:
- **["Pattern Recognition and Machine Learning" by Christopher M. Bishop](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)**
- **["An Introduction to Statistical Learning" by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani](https://www.stat.berkeley.edu/users/rabbee/s154/ISLR_First_Printing.pdf)**
- **["Machine Learning: A Probabilistic Perspective" by Kevin P. Murphy](https://probml.github.io/pml-book/book0.html)**

### Further Exploration:
- **Scikit-Learn Documentation:** Explore practical examples of supervised and unsupervised learning [here](https://scikit-learn.org/stable/).